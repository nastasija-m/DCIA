{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob \n",
    "import statsmodels.api as sm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all  parquet files in the folder and store them in a dataframe\n",
    "df = pd.concat([pd.read_parquet(f) for f in glob.glob(r'C:\\Users\\nasta\\OneDrive - TU Eindhoven\\Desktop\\DCIA\\Data-20230329T105410Z-001\\Data\\*.parquet')], ignore_index = True)\n",
    "df['date_code'] = pd.to_datetime(df['date_code'], format='%Y%m%d',errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nasta\\AppData\\Local\\Temp\\ipykernel_32344\\2342225733.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2['LP'] = 1\n",
      "C:\\Users\\nasta\\AppData\\Local\\Temp\\ipykernel_32344\\2342225733.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_4['LP'] = 1\n",
      "C:\\Users\\nasta\\AppData\\Local\\Temp\\ipykernel_32344\\2342225733.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_1['LP'] = 0\n",
      "C:\\Users\\nasta\\AppData\\Local\\Temp\\ipykernel_32344\\2342225733.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_3['LP'] = 0\n"
     ]
    }
   ],
   "source": [
    "#split df into two dataframes, one for period_code = 3 and 4 and one for period_code = 1 and 2\n",
    "df_1 = df[df['period_code']==1]\n",
    "df_2 = df[df['period_code']==2]\n",
    "df_3 = df[df['period_code']==3]\n",
    "df_4 = df[df['period_code']==4]\n",
    "\n",
    "#indicate whater the point is in LP period or not \n",
    "df_2['LP'] = 1\n",
    "df_4['LP'] = 1\n",
    "df_1['LP'] = 0\n",
    "df_3['LP'] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nasta\\AppData\\Local\\Temp\\ipykernel_20996\\999605109.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_4['new_customer'] = ~df_4['customer_code'].isin(existing_customers)*1\n"
     ]
    }
   ],
   "source": [
    "existing_customers = pd.concat([df_1['customer_code'], df_2['customer_code'], df_3['customer_code']])\n",
    "df_4['new_customer'] = ~df_4['customer_code'].isin(existing_customers)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#treatment group: new customers in df_post during LP_period = 1\n",
    "#control group: new customers in df_pre during LP_period = 1\n",
    "# x: treatment (LP_period = 1)\n",
    "# y: New customers per day \n",
    "\n",
    "#assumption: the new customer is new only on the day it visited the store for the fisrt time\n",
    "\n",
    "#idea: measure loyalty of new customers by seeing how many times they visit the store after their first visit?\n",
    "#do we have an objective if old customers started coming more often then before during the LP period?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_code</th>\n",
       "      <th>period_code</th>\n",
       "      <th>redeemer_latest_ind</th>\n",
       "      <th>customer_code</th>\n",
       "      <th>customer_segment_level_1_code</th>\n",
       "      <th>customer_segment_level_2_code</th>\n",
       "      <th>revenue_after_discount_incl_vat</th>\n",
       "      <th>quantity_sold</th>\n",
       "      <th>store_type_new</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-06-29</th>\n",
       "      <td>212</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>946530</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2188.0</td>\n",
       "      <td>5.718</td>\n",
       "      <td>Hypermarket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-29</th>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1433460</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2312.0</td>\n",
       "      <td>12.234</td>\n",
       "      <td>Hypermarket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-29</th>\n",
       "      <td>279</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17980</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2838.0</td>\n",
       "      <td>15.864</td>\n",
       "      <td>Hypermarket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-29</th>\n",
       "      <td>323</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1365490</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3156.0</td>\n",
       "      <td>12.594</td>\n",
       "      <td>Daily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-29</th>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>932800</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>Hypermarket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-03</th>\n",
       "      <td>297</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1183790</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5702.7</td>\n",
       "      <td>13.315</td>\n",
       "      <td>Online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-03</th>\n",
       "      <td>254</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1382000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1179.0</td>\n",
       "      <td>5.000</td>\n",
       "      <td>Hypermarket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-03</th>\n",
       "      <td>417</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1032270</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3596.0</td>\n",
       "      <td>12.000</td>\n",
       "      <td>Daily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-03</th>\n",
       "      <td>241</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1407790</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1966.0</td>\n",
       "      <td>3.118</td>\n",
       "      <td>Hypermarket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-03</th>\n",
       "      <td>321</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1188220</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1599.0</td>\n",
       "      <td>10.000</td>\n",
       "      <td>Daily</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3252967 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            store_code  period_code  redeemer_latest_ind  customer_code  \\\n",
       "date_code                                                                 \n",
       "2020-06-29         212            1                    0         946530   \n",
       "2020-06-29         365            1                    1        1433460   \n",
       "2020-06-29         279            1                    1          17980   \n",
       "2020-06-29         323            1                    1        1365490   \n",
       "2020-06-29         256            1                    0         932800   \n",
       "...                ...          ...                  ...            ...   \n",
       "2022-04-03         297            4                    1        1183790   \n",
       "2022-04-03         254            4                    0        1382000   \n",
       "2022-04-03         417            4                    0        1032270   \n",
       "2022-04-03         241            4                    0        1407790   \n",
       "2022-04-03         321            4                    1        1188220   \n",
       "\n",
       "            customer_segment_level_1_code  customer_segment_level_2_code  \\\n",
       "date_code                                                                  \n",
       "2020-06-29                            1.0                            1.0   \n",
       "2020-06-29                            1.0                            1.0   \n",
       "2020-06-29                            3.0                            6.0   \n",
       "2020-06-29                            1.0                            1.0   \n",
       "2020-06-29                            3.0                            6.0   \n",
       "...                                   ...                            ...   \n",
       "2022-04-03                            1.0                            1.0   \n",
       "2022-04-03                            3.0                            6.0   \n",
       "2022-04-03                            2.0                            2.0   \n",
       "2022-04-03                            2.0                            5.0   \n",
       "2022-04-03                            3.0                            6.0   \n",
       "\n",
       "            revenue_after_discount_incl_vat  quantity_sold store_type_new  \n",
       "date_code                                                                  \n",
       "2020-06-29                           2188.0          5.718    Hypermarket  \n",
       "2020-06-29                           2312.0         12.234    Hypermarket  \n",
       "2020-06-29                           2838.0         15.864    Hypermarket  \n",
       "2020-06-29                           3156.0         12.594          Daily  \n",
       "2020-06-29                            310.0          2.000    Hypermarket  \n",
       "...                                     ...            ...            ...  \n",
       "2022-04-03                           5702.7         13.315         Online  \n",
       "2022-04-03                           1179.0          5.000    Hypermarket  \n",
       "2022-04-03                           3596.0         12.000          Daily  \n",
       "2022-04-03                           1966.0          3.118    Hypermarket  \n",
       "2022-04-03                           1599.0         10.000          Daily  \n",
       "\n",
       "[3252967 rows x 9 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.groupby\n",
    "#df['date_code'].dt\n",
    "df.sort_values(by=['date_code'],inplace=True)\n",
    "df.set_index('date_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nasta\\anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1918: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.sqrt(eigvals[0]/eigvals[-1])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>revenue_after_discount_incl_vat</td> <th>  R-squared:         </th>  <td>   0.000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                          <td>OLS</td>               <th>  Adj. R-squared:    </th>  <td>   0.000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                    <td>Least Squares</td>          <th>  F-statistic:       </th>  <td>     nan</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>                    <td>Wed, 29 Mar 2023</td>         <th>  Prob (F-statistic):</th>   <td>   nan</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                        <td>13:24:55</td>             <th>  Log-Likelihood:    </th> <td>-1.5898e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>             <td>1601247</td>             <th>  AIC:               </th>  <td>3.180e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>                 <td>1601246</td>             <th>  BIC:               </th>  <td>3.180e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>                     <td>     0</td>              <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>             <td>nonrobust</td>            <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> 2818.6332</td> <td>    3.920</td> <td>  718.953</td> <td> 0.000</td> <td> 2810.949</td> <td> 2826.317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LP_period</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>3435527.653</td> <th>  Durbin-Watson:     </th>     <td>   1.967</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>    <th>  Jarque-Bera (JB):  </th> <td>119601071821.625</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td>18.258</td>    <th>  Prob(JB):          </th>     <td>    0.00</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>1341.389</td>   <th>  Cond. No.          </th>     <td>     inf</td>    \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is      0. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                   OLS Regression Results                                  \n",
       "===========================================================================================\n",
       "Dep. Variable:     revenue_after_discount_incl_vat   R-squared:                       0.000\n",
       "Model:                                         OLS   Adj. R-squared:                  0.000\n",
       "Method:                              Least Squares   F-statistic:                       nan\n",
       "Date:                             Wed, 29 Mar 2023   Prob (F-statistic):                nan\n",
       "Time:                                     13:24:55   Log-Likelihood:            -1.5898e+07\n",
       "No. Observations:                          1601247   AIC:                         3.180e+07\n",
       "Df Residuals:                              1601246   BIC:                         3.180e+07\n",
       "Df Model:                                        0                                         \n",
       "Covariance Type:                         nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   2818.6332      3.920    718.953      0.000    2810.949    2826.317\n",
       "LP_period           0          0        nan        nan           0           0\n",
       "==============================================================================\n",
       "Omnibus:                  3435527.653   Durbin-Watson:                   1.967\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):     119601071821.625\n",
       "Skew:                          18.258   Prob(JB):                         0.00\n",
       "Kurtosis:                    1341.389   Cond. No.                          inf\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is      0. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply regression discontinuity for predicting the effect of period_code = 4 on revenue_after_discount_incl_vat\n",
    "re = smf.ols(formula = \"new_customer ~ LP_period \", data = ).fit()\n",
    "re.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nasta\\AppData\\Local\\Temp\\ipykernel_32344\\2846312335.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  week_df['week'] = week_df.apply(lambda x: get_week(x['date_code'], x['period_code']), axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame with the necessary columns\n",
    "new_df = df[['date_code', 'period_code', 'customer_code', 'revenue_after_discount_incl_vat']]\n",
    "\n",
    "# Aggregate the data by date and period\n",
    "new_df = new_df.groupby(['date_code', 'period_code']).agg({'customer_code': 'count', 'revenue_after_discount_incl_vat': 'sum'})\n",
    "\n",
    "# Rename the aggregated columns\n",
    "new_df = new_df.rename(columns={'customer_code': 'num_customers', 'revenue_after_discount_incl_vat': 'total_revenue'})\n",
    "\n",
    "# Create a new DataFrame with the necessary columns\n",
    "week_df = df[['date_code', 'period_code']]\n",
    "\n",
    "# Get the start date for each period\n",
    "start_dates = week_df.groupby('period_code').agg({'date_code': 'min'})\n",
    "\n",
    "# Create a dictionary mapping period codes to start dates\n",
    "start_date_dict = start_dates.to_dict()['date_code']\n",
    "\n",
    "# Define a function to calculate the week number for a given date and period\n",
    "def get_week(date, period):\n",
    "    start_date = start_date_dict[period]\n",
    "    days_since_start = (date - start_date).days\n",
    "    week = (days_since_start // 7) + 1\n",
    "    return week\n",
    "\n",
    "#Apply the get_week function to each row in the DataFrame\n",
    "week_df['week'] = week_df.apply(lambda x: get_week(x['date_code'], x['period_code']), axis=1)\n",
    "\n",
    "# Merge the week column back into the new_df DataFrame\n",
    "new_df = pd.merge(new_df, week_df[['date_code', 'period_code', 'week']], on=['date_code', 'period_code'])\n",
    "\n",
    "# Reset the index to create separate columns for date and period\n",
    "new_df = new_df.reset_index()\n",
    "\n",
    "new_df['treatment'] = ((new_df['period_code'] == 4)).astype(int)\n",
    "\n",
    "# create a binary indicator column for the post-treatment period\n",
    "new_df['post'] = (new_df['period_code'] > 2).astype(int)\n",
    "\n",
    "# create an interaction term between treatment and post\n",
    "new_df['treatment_post'] = new_df['treatment'] * new_df['post']\n",
    "\n",
    "\n",
    "# create an interaction term between week and post\n",
    "new_df['week_post'] = new_df['post'] * new_df['week']\n",
    "#make a dummyfy the varaible week_post\n",
    "new_df = pd.get_dummies(new_df, columns=['week'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          num_customers   R-squared:                       0.020\n",
      "Model:                            OLS   Adj. R-squared:                  0.020\n",
      "Method:                 Least Squares   F-statistic:                 3.321e+04\n",
      "Date:                Thu, 13 Apr 2023   Prob (F-statistic):               0.00\n",
      "Time:                        13:25:47   Log-Likelihood:            -2.5779e+07\n",
      "No. Observations:             3252967   AIC:                         5.156e+07\n",
      "Df Residuals:                 3252964   BIC:                         5.156e+07\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const           5973.9432      0.521   1.15e+04      0.000    5972.923    5974.964\n",
      "post            -225.5137      0.912   -247.227      0.000    -227.302    -223.726\n",
      "treatment_post    89.4026      1.057     84.548      0.000      87.330      91.475\n",
      "==============================================================================\n",
      "Omnibus:                   815228.496   Durbin-Watson:                   0.000\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          6857932.708\n",
      "Skew:                           0.973   Prob(JB):                         0.00\n",
      "Kurtosis:                       9.842   Cond. No.                         4.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# fit a linear regression model with the interaction term and other covariates\n",
    "X = new_df[['post', 'treatment_post']]\n",
    "X = sm.add_constant(X)\n",
    "y = new_df['num_customers']\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# print the regression results\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set display options to show all rows and columns\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          num_customers   R-squared:                       0.117\n",
      "Model:                            OLS   Adj. R-squared:                  0.117\n",
      "Method:                 Least Squares   F-statistic:                 1.955e+04\n",
      "Date:                Thu, 13 Apr 2023   Prob (F-statistic):               0.00\n",
      "Time:                        13:24:40   Log-Likelihood:            -2.5610e+07\n",
      "No. Observations:             3252967   AIC:                         5.122e+07\n",
      "Df Residuals:                 3252944   BIC:                         5.122e+07\n",
      "Df Model:                          22                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const          -2.708e+09   5.49e+10     -0.049      0.961    -1.1e+11    1.05e+11\n",
      "post            -221.6114      0.866   -255.873      0.000    -223.309    -219.914\n",
      "treatment_post    79.8987      1.004     79.559      0.000      77.930      81.867\n",
      "week_1          2.708e+09   5.49e+10      0.049      0.961   -1.05e+11     1.1e+11\n",
      "week_2          2.708e+09   5.49e+10      0.049      0.961   -1.05e+11     1.1e+11\n",
      "week_3          2.708e+09   5.49e+10      0.049      0.961   -1.05e+11     1.1e+11\n",
      "week_4          2.708e+09   5.49e+10      0.049      0.961   -1.05e+11     1.1e+11\n",
      "week_5          2.708e+09   5.49e+10      0.049      0.961   -1.05e+11     1.1e+11\n",
      "week_6          2.708e+09   5.49e+10      0.049      0.961   -1.05e+11     1.1e+11\n",
      "week_7          2.708e+09   5.49e+10      0.049      0.961   -1.05e+11     1.1e+11\n",
      "week_8          2.708e+09   5.49e+10      0.049      0.961   -1.05e+11     1.1e+11\n",
      "week_9          2.708e+09   5.49e+10      0.049      0.961   -1.05e+11     1.1e+11\n",
      "week_10         2.708e+09   5.49e+10      0.049      0.961   -1.05e+11     1.1e+11\n",
      "week_11         2.708e+09   5.49e+10      0.049      0.961   -1.05e+11     1.1e+11\n",
      "week_12         2.708e+09   5.49e+10      0.049      0.961   -1.05e+11     1.1e+11\n",
      "week_13         2.708e+09   5.49e+10      0.049      0.961   -1.05e+11     1.1e+11\n",
      "week_14         2.708e+09   5.49e+10      0.049      0.961   -1.05e+11     1.1e+11\n",
      "week_15         2.708e+09   5.49e+10      0.049      0.961   -1.05e+11     1.1e+11\n",
      "week_16         2.708e+09   5.49e+10      0.049      0.961   -1.05e+11     1.1e+11\n",
      "week_17         2.708e+09   5.49e+10      0.049      0.961   -1.05e+11     1.1e+11\n",
      "week_18         2.708e+09   5.49e+10      0.049      0.961   -1.05e+11     1.1e+11\n",
      "week_19         2.708e+09   5.49e+10      0.049      0.961   -1.05e+11     1.1e+11\n",
      "week_20         2.708e+09   5.49e+10      0.049      0.961   -1.05e+11     1.1e+11\n",
      "==============================================================================\n",
      "Omnibus:                   443867.387   Durbin-Watson:                   0.000\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          4399524.233\n",
      "Skew:                           0.321   Prob(JB):                         0.00\n",
      "Kurtosis:                       8.661   Cond. No.                     8.58e+11\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 6.38e-18. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "#maximize the length of the output \n",
    "pd\n",
    "# fit a linear regression model with the interaction term and other covariates\n",
    "X = new_df[['post', 'treatment_post', 'week_1', 'week_2',\n",
    "       'week_3', 'week_4', 'week_5', 'week_6', 'week_7', 'week_8', 'week_9',\n",
    "       'week_10', 'week_11', 'week_12', 'week_13', 'week_14', 'week_15',\n",
    "       'week_16', 'week_17', 'week_18', 'week_19', 'week_20']]\n",
    "X = sm.add_constant(X)\n",
    "y = new_df['num_customers']\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# print the regression results\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          total_revenue   R-squared:                       0.165\n",
      "Model:                            OLS   Adj. R-squared:                  0.165\n",
      "Method:                 Least Squares   F-statistic:                 2.795e+04\n",
      "Date:                Thu, 13 Apr 2023   Prob (F-statistic):               0.00\n",
      "Time:                        13:18:16   Log-Likelihood:            -5.4736e+07\n",
      "No. Observations:             3252967   AIC:                         1.095e+08\n",
      "Df Residuals:                 3252943   BIC:                         1.095e+08\n",
      "Df Model:                          23                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const          -7.133e+15   1.26e+16     -0.566      0.572   -3.18e+16    1.76e+16\n",
      "post            7.247e+15   1.26e+16      0.576      0.565   -1.74e+16    3.19e+16\n",
      "treatment_post  3.496e+06   7771.596    449.906      0.000    3.48e+06    3.51e+06\n",
      "week_post_0     7.133e+15   1.26e+16      0.566      0.572   -1.76e+16    3.18e+16\n",
      "week_post_1     -1.14e+14   8.16e+14     -0.140      0.889   -1.71e+15    1.49e+15\n",
      "week_post_2     -1.14e+14   8.16e+14     -0.140      0.889   -1.71e+15    1.49e+15\n",
      "week_post_3     -1.14e+14   8.16e+14     -0.140      0.889   -1.71e+15    1.49e+15\n",
      "week_post_4     -1.14e+14   8.16e+14     -0.140      0.889   -1.71e+15    1.49e+15\n",
      "week_post_5     -1.14e+14   8.16e+14     -0.140      0.889   -1.71e+15    1.49e+15\n",
      "week_post_6     -1.14e+14   8.16e+14     -0.140      0.889   -1.71e+15    1.49e+15\n",
      "week_post_7     -1.14e+14   8.16e+14     -0.140      0.889   -1.71e+15    1.49e+15\n",
      "week_post_8     -1.14e+14   8.16e+14     -0.140      0.889   -1.71e+15    1.49e+15\n",
      "week_post_9     -1.14e+14   8.16e+14     -0.140      0.889   -1.71e+15    1.49e+15\n",
      "week_post_10    -1.14e+14   8.16e+14     -0.140      0.889   -1.71e+15    1.49e+15\n",
      "week_post_11    -1.14e+14   8.16e+14     -0.140      0.889   -1.71e+15    1.49e+15\n",
      "week_post_12    -1.14e+14   8.16e+14     -0.140      0.889   -1.71e+15    1.49e+15\n",
      "week_post_13    -1.14e+14   8.16e+14     -0.140      0.889   -1.71e+15    1.49e+15\n",
      "week_post_14    -1.14e+14   8.16e+14     -0.140      0.889   -1.71e+15    1.49e+15\n",
      "week_post_15    -1.14e+14   8.16e+14     -0.140      0.889   -1.71e+15    1.49e+15\n",
      "week_post_16    -1.14e+14   8.16e+14     -0.140      0.889   -1.71e+15    1.49e+15\n",
      "week_post_17    -1.14e+14   8.16e+14     -0.140      0.889   -1.71e+15    1.49e+15\n",
      "week_post_18    -1.14e+14   8.16e+14     -0.140      0.889   -1.71e+15    1.49e+15\n",
      "week_post_19    -1.14e+14   8.16e+14     -0.140      0.889   -1.71e+15    1.49e+15\n",
      "week_post_20    -1.14e+14   8.16e+14     -0.140      0.889   -1.71e+15    1.49e+15\n",
      "==============================================================================\n",
      "Omnibus:                  3012645.893   Durbin-Watson:                   0.000\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):        159582560.100\n",
      "Skew:                           4.413   Prob(JB):                         0.00\n",
      "Kurtosis:                      36.159   Cond. No.                     1.01e+13\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 5.07e-20. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "const                      NaN\n",
      "post              7.247436e+15\n",
      "treatment_post    3.496486e+06\n",
      "week_post_0       7.133440e+15\n",
      "week_post_1      -1.139961e+14\n",
      "week_post_2      -1.139961e+14\n",
      "week_post_3      -1.139961e+14\n",
      "week_post_4      -1.139961e+14\n",
      "week_post_5      -1.139961e+14\n",
      "week_post_6      -1.139961e+14\n",
      "week_post_7      -1.139961e+14\n",
      "week_post_8      -1.139961e+14\n",
      "week_post_9      -1.139961e+14\n",
      "week_post_10     -1.139961e+14\n",
      "week_post_11     -1.139961e+14\n",
      "week_post_12     -1.139961e+14\n",
      "week_post_13     -1.139961e+14\n",
      "week_post_14     -1.139961e+14\n",
      "week_post_15     -1.139961e+14\n",
      "week_post_16     -1.139961e+14\n",
      "week_post_17     -1.139961e+14\n",
      "week_post_18     -1.139961e+14\n",
      "week_post_19     -1.139961e+14\n",
      "week_post_20     -1.139961e+14\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# fit a linear regression model with the interaction term and other covariates\n",
    "X = new_df[['post', 'treatment_post', 'week_post_0',\n",
    "       'week_post_1', 'week_post_2', 'week_post_3', 'week_post_4',\n",
    "       'week_post_5', 'week_post_6', 'week_post_7', 'week_post_8',\n",
    "       'week_post_9', 'week_post_10', 'week_post_11', 'week_post_12',\n",
    "       'week_post_13', 'week_post_14', 'week_post_15', 'week_post_16',\n",
    "       'week_post_17', 'week_post_18', 'week_post_19', 'week_post_20']]\n",
    "X = sm.add_constant(X)\n",
    "y = new_df['total_revenue']\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# print the regression results\n",
    "print(model.summary())\n",
    "# compute the standard deviations of the predictor variables\n",
    "X_std = (X - X.mean()) / X.std()\n",
    "\n",
    "# divide the coefficients by the standard deviations\n",
    "coef_std = model.params / X_std.std()\n",
    "\n",
    "# print the standardized coefficients\n",
    "print(coef_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          total_revenue   R-squared:                       0.056\n",
      "Model:                            OLS   Adj. R-squared:                  0.056\n",
      "Method:                 Least Squares   F-statistic:                 9.682e+04\n",
      "Date:                Thu, 13 Apr 2023   Prob (F-statistic):               0.00\n",
      "Time:                        13:26:24   Log-Likelihood:            -5.4935e+07\n",
      "No. Observations:             3252967   AIC:                         1.099e+08\n",
      "Df Residuals:                 3252964   BIC:                         1.099e+08\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const           1.619e+07   4064.439   3984.321      0.000    1.62e+07    1.62e+07\n",
      "post           -1.575e+06   7121.984   -221.209      0.000   -1.59e+06   -1.56e+06\n",
      "treatment_post  3.617e+06   8256.051    438.100      0.000     3.6e+06    3.63e+06\n",
      "==============================================================================\n",
      "Omnibus:                  3392885.158   Durbin-Watson:                   0.000\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):        210046050.390\n",
      "Skew:                           5.345   Prob(JB):                         0.00\n",
      "Kurtosis:                      40.887   Cond. No.                         4.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "const                      NaN\n",
      "post             -1.575445e+06\n",
      "treatment_post    3.616977e+06\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# fit a linear regression model with the interaction term and other covariates\n",
    "X = new_df[['post', 'treatment_post']]\n",
    "X = sm.add_constant(X)\n",
    "y = new_df['total_revenue']\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# print the regression results\n",
    "print(model.summary())\n",
    "# compute the standard deviations of the predictor variables\n",
    "X_std = (X - X.mean()) / X.std()\n",
    "\n",
    "# divide the coefficients by the standard deviations\n",
    "coef_std = model.params / X_std.std()\n",
    "\n",
    "# print the standardized coefficients\n",
    "print(coef_std)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86b531af68b5975560c6169243fcb20e1af83837e051d7563f0ced09878167a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
